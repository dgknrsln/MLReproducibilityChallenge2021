{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blg561e_final_project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFToNDeuqE9v"
      },
      "source": [
        "# VL-T5 inference on custom images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSUhoRppsQI"
      },
      "source": [
        "## Download code and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /env/python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VcPxhjlTrrZM",
        "outputId": "b80a6659-5aee-4dba-bace-135d01245703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/env/python': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JMqvnesGnXG",
        "outputId": "ee00b057-c1a3-4608-d7c7-aaf1a55f6790"
      },
      "source": [
        "!git clone https://github.com/j-min/VL-T5\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VL-T5'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 229 (delta 132), reused 177 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (229/229), 900.48 KiB | 7.26 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFwDNTs2RwVo",
        "outputId": "97b04301-b4d4-4104-95c4-fc12b197cdca"
      },
      "source": [
        "cd VL-T5/\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VL-T5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n42_sfxXByh",
        "outputId": "34aa3ccb-f9cd-41c9-86fa-455bb1b96467"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "assets\t\t       feature_extraction\tREADME.md\t  VL-T5\n",
            "download_backbones.py  inference_example.ipynb\trequirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U25Mz51oRxJH",
        "outputId": "39b5c729-bc31-4f13-e56d-84c3369d5794"
      },
      "source": [
        "!pip uninstall param -y # to resolve name conflict with src.param.py\n",
        "!pip install -r requirements.txt\n",
        "!python download_backbones.py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: param 1.12.0\n",
            "Uninstalling param-1.12.0:\n",
            "  Successfully uninstalled param-1.12.0\n",
            "Collecting git+git://github.com/j-min/language-evaluation@master (from -r requirements.txt (line 12))\n",
            "  Cloning git://github.com/j-min/language-evaluation (to revision master) to /tmp/pip-req-build-1h7vraqy\n",
            "  Running command git clone -q git://github.com/j-min/language-evaluation /tmp/pip-req-build-1h7vraqy\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 20 kB/s \n",
            "\u001b[?25hCollecting transformers==4.2.1\n",
            "  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 37.1 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (3.1.0)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 34.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (3.13)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.7 MB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 43.2 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r requirements.txt (line 12)) (0.18.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r requirements.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r requirements.txt (line 12)) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r requirements.txt (line 12)) (8.12.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (21.3)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 40.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (3.4.0)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 40.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r requirements.txt (line 2)) (4.8.2)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0->-r requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r requirements.txt (line 4)) (1.5.2)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 6.6 MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (3.17.3)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.1-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 44.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (5.4.8)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r requirements.txt (line 5)) (7.1.2)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.24-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 44.7 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r requirements.txt (line 5)) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r requirements.txt (line 9)) (0.11.0)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r requirements.txt (line 11)) (0.8.9)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1->-r requirements.txt (line 2)) (3.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1->-r requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r requirements.txt (line 12)) (2.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r requirements.txt (line 12)) (2021.11.2)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r requirements.txt (line 12)) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r requirements.txt (line 12)) (1.2.0)\n",
            "Building wheels for collected packages: language-evaluation, subprocess32, wget, pathtools\n",
            "  Building wheel for language-evaluation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for language-evaluation: filename=language_evaluation-0.1.0-py3-none-any.whl size=42700525 sha256=632953f8ba8f1acec29837c64632bdbae09cc19f13dfbfe35c77645a0e30981e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qdh113c4/wheels/8d/fd/6b/f12f08f2fca4312f96a38e1df7c5f5fbebb59480def23f6cb7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=c1da15f695925ea050fc9d63959dc96943996bceec842535b1788fdf1001f7f2\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9672 sha256=3a11af35ecff18a3bf57e3c6fcdecc29db6c91706389aa2fb3ed76c5da698de1\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8807 sha256=d2a4c6d4ed323f53216be5f9d36dcad05c024dd75ddb30324aa127cc2a0ddec4\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built language-evaluation subprocess32 wget pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, torch, tokenizers, subprocess32, shortuuid, sentry-sdk, sacremoses, portalocker, pathtools, GitPython, docker-pycreds, configparser, colorlog, colorama, wget, wandb, transformers, torchvision, sentencepiece, sacrebleu, language-evaluation\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.24 colorama-0.4.4 colorlog-6.6.0 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 language-evaluation-0.1.0 pathtools-0.1.2 portalocker-2.3.2 sacrebleu-2.0.0 sacremoses-0.0.46 sentencepiece-0.1.96 sentry-sdk-1.5.1 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 tokenizers-0.9.4 torch-1.6.0 torchvision-0.7.0 transformers-4.2.1 wandb-0.12.9 wget-3.2 yaspin-2.1.0\n",
            "Downloading checkpoints if not cached\n",
            "T5-base\n",
            "Downloading: 100% 1.20k/1.20k [00:00<00:00, 994kB/s]\n",
            "Downloading: 100% 892M/892M [00:23<00:00, 37.7MB/s]\n",
            "Downloading: 100% 792k/792k [00:00<00:00, 5.06MB/s]\n",
            "BART-base\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 5.56MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.11MB/s]\n",
            "Downloading: 100% 1.69k/1.69k [00:00<00:00, 1.70MB/s]\n",
            "Downloading: 100% 558M/558M [00:14<00:00, 38.2MB/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIcGYw4HqSGW"
      },
      "source": [
        "## Download the pretrained checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdBlncooUJY4"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd VL-T5/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OUH7REzKWlzl",
        "outputId": "1a6e5a8b-7b59-4012-9520-7a3549d410fa"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VL-T5/VL-T5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXR4YwyiUvp7"
      },
      "source": [
        "!mkdir -p snap/pretrain/VLBart\n",
        "!mkdir -p snap/pretrain/VLT5\n",
        "!mkdir -p snap/vcr_pretrain/VLBart\n",
        "!mkdir -p snap/vcr_pretrain/VLT5"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "X1aNEiF3UkRE",
        "outputId": "beab8a00-a225-43db-b583-ed84ae51aa1f"
      },
      "source": [
        "gdown.download('https://drive.google.com/uc?id=100qajGncE_vc4bfjVxxICwz3dwiAxbIZ', 'snap/pretrain/VLT5/Epoch30.pth', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1fTKGCBfMe2eJ_rivPQu0YkNJTNdv_0aq', 'snap/pretrain/VLBart/Epoch30.pth', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1jXyMnJJqwrIrHk62WB_ye0dPxBNvIoe5', 'snap/vcr_pretrain/VLT5/Epoch20.pth', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1urZFOZTpXuMbU_Q697fwGdmg36an7LDP', 'snap/vcr_pretrain/VLBart/Epoch20.pth', quiet=False)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=100qajGncE_vc4bfjVxxICwz3dwiAxbIZ\n",
            "To: /content/VL-T5/VL-T5/snap/pretrain/VLT5/Epoch30.pth\n",
            "100%|██████████| 898M/898M [00:06<00:00, 128MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1fTKGCBfMe2eJ_rivPQu0YkNJTNdv_0aq\n",
            "To: /content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30.pth\n",
            "100%|██████████| 565M/565M [00:11<00:00, 47.5MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'snap/pretrain/VLBart/Epoch30.pth'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcXsM8fzxozN"
      },
      "source": [
        "Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZQxFrEy4FV",
        "outputId": "3ec7aba2-5178-448f-e9ba-e2888851c922"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls /content/gdrive/MyDrive/datasets"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "COCO  flickr30k  GQA  lxmert  nlvr  RefCOCO  VCR  VG  vqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !mkdir -p /content/VL-T5/"
      ],
      "metadata": {
        "id": "3wrbFQrWZrhD"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/gdrive/MyDrive/datasets' '/content/VL-T5'\n",
        "!ls /content/VL-T5/datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOW8Zyb6Ypzm",
        "outputId": "a28bcf3e-a6dd-45f8-b9e3-cee2dbeac514"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCO  flickr30k  GQA  lxmert  nlvr  RefCOCO  VCR  VG  vqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash scripts/COCOCaption_VLT5.sh 1\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic3Zl3Jtdi2p",
        "outputId": "8fece5a3-3f78-477e-d07b-8f62ad3167d6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Configurations\n",
            "{'RefCOCO_BUTD': False,\n",
            " 'RefCOCO_GT': False,\n",
            " 'adam_beta1': 0.9,\n",
            " 'adam_beta2': 0.999,\n",
            " 'adam_eps': 1e-06,\n",
            " 'answer_normalize': False,\n",
            " 'backbone': 't5-base',\n",
            " 'batch_size': 80,\n",
            " 'caption_cocoonly': True,\n",
            " 'caption_only': False,\n",
            " 'classifier': False,\n",
            " 'clip_grad_norm': 5.0,\n",
            " 'coco_only': False,\n",
            " 'comment': '',\n",
            " 'distributed': True,\n",
            " 'do_lower_case': False,\n",
            " 'dropout': 0.1,\n",
            " 'dry': False,\n",
            " 'epochs': 20,\n",
            " 'feat_dim': 2048,\n",
            " 'fp16': False,\n",
            " 'from_scratch': False,\n",
            " 'gen_max_length': 20,\n",
            " 'gradient_accumulation_steps': 1,\n",
            " 'ground_upsample': 1,\n",
            " 'ground_weight': 1,\n",
            " 'individual_vis_layer_norm': True,\n",
            " 'itm_cocoonly': True,\n",
            " 'load': 'snap/pretrain/VLT5/Epoch30',\n",
            " 'local_rank': 0,\n",
            " 'log_train_accuracy': False,\n",
            " 'losses': 'lm,obj,attr,feat',\n",
            " 'lr': 5e-05,\n",
            " 'max_n_boxes': 36,\n",
            " 'max_text_length': 20,\n",
            " 'multiGPU': True,\n",
            " 'multitask_sampling': 'roundrobin',\n",
            " 'n_boxes': 36,\n",
            " 'n_ground': 1,\n",
            " 'no_prefix': False,\n",
            " 'num_beams': 5,\n",
            " 'num_workers': 4,\n",
            " 'obj_mask_rate': 0.15,\n",
            " 'optim': 'adamw',\n",
            " 'optimizer': 'adamw',\n",
            " 'oscar_tags': False,\n",
            " 'output': 'snap/COCOCaption/VLT5',\n",
            " 'pos_dim': 4,\n",
            " 'prefix': None,\n",
            " 'raw_label': False,\n",
            " 'seed': 9595,\n",
            " 'share_vis_lang_layer_norm': False,\n",
            " 'shuffle_boxes': False,\n",
            " 'single_vqa_prefix': False,\n",
            " 'submit': False,\n",
            " 'tasks': '',\n",
            " 'test': 'karpathy_test',\n",
            " 'test_answerable': False,\n",
            " 'test_only': False,\n",
            " 'tokenizer': None,\n",
            " 'train': 'karpathy_train',\n",
            " 'train_topk': -1,\n",
            " 'use_vis_layer_norm': True,\n",
            " 'use_vis_order_embedding': True,\n",
            " 'use_vision': True,\n",
            " 'valid': 'karpathy_val',\n",
            " 'valid_batch_size': 100,\n",
            " 'valid_topk': -1,\n",
            " 'warmup_ratio': 0.1,\n",
            " 'weight_decay': 0.01,\n",
            " 'word_mask_rate': 0.15,\n",
            " 'world_size': 1}\n",
            "Process Launching at GPU 0\n",
            "Building train loader at GPU 0\n",
            "Data source:  karpathy_train\n",
            "karpathy_train has 113287 images\n",
            "Loaded 566747 data from karpathy_train\n",
            "# all sentences: 566747\n",
            "Building val loader at GPU 0\n",
            "Data source:  karpathy_val\n",
            "karpathy_val has 5000 images\n",
            "Loaded 5000 data from karpathy_val\n",
            "# all sentences: 5000\n",
            "# len val loader: 50\n",
            "Building test loader at GPU 0\n",
            "Data source:  karpathy_test\n",
            "karpathy_test has 5000 images\n",
            "Loaded 5000 data from karpathy_test\n",
            "# all sentences: 5000\n",
            "Building Model at GPU 0\n",
            "Model loaded from  snap/pretrain/VLT5/Epoch30.pth\n",
            "_IncompatibleKeys(missing_keys=[], unexpected_keys=['encoder.visual_embedding.layer_norm.weight'])\n",
            "Model Launching at GPU 0\n",
            "Building Optimizer\n",
            "Batch per epoch: 7085\n",
            "Total Iters: 141700\n",
            "Warmup ratio: 0.1\n",
            "Warm up Iters: 14170\n",
            "It took 3.3s\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (1) Create a W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (2) Use an existing W&B account\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: (3) Don't visualize my results\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Enter your choice: 3\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You chose 'Don't visualize my results'\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Run `wandb online` or set WANDB_MODE=online to enable cloud syncing.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 39 files into the W&B run directory, call wandb.save again to sync new files.\n",
            "Epoch 0 | LR 0.000000 | Steps 4 | Loss 6.937285:   0%|                            | 4/7085 [15:30<256:42:24, 130.51s/it]Traceback (most recent call last):\n",
            "  File \"src/caption.py\", line 467, in <module>\n",
            "    main_worker(args.local_rank, args)\n",
            "  File \"src/caption.py\", line 436, in main_worker\n",
            "    trainer.train()\n",
            "  File \"src/caption.py\", line 167, in train\n",
            "    for step_i, batch in enumerate(self.train_loader):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 363, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 989, in _next_data\n",
            "    return self._process_data(data)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 1014, in _process_data\n",
            "    data.reraise()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/_utils.py\", line 395, in reraise\n",
            "    raise self.exc_type(msg)\n",
            "KeyError: Caught KeyError in DataLoader worker process 0.\n",
            "Original Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n",
            "    data = fetcher.fetch(index)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/VL-T5/VL-T5/src/caption_data.py\", line 176, in __getitem__\n",
            "    img_h = f[f'{img_id}/img_h'][()]\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\", line 288, in __getitem__\n",
            "    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n",
            "  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n",
            "  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\n",
            "KeyError: \"Unable to open object (file read failed: time = Wed Dec 22 19:39:30 2021\\n, filename = '/content/gdrive/.shortcut-targets-by-id/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf/datasets/COCO/features/train2014_obj36.h5', file descriptor = 53, errno = 28, error message = 'No space left on device', buf = 0x565006d85c00, total read size = 512, bytes this sub-read = 512, bytes actually read = 18446744073709551615, offset = 0)\"\n",
            "\n",
            "\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish, PID 947... (failed 1).\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can sync this run to the cloud by running:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mwandb sync /content/VL-T5/VL-T5/wandb/offline-run-20211222_192214-3go72k41\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[0mFind logs at: ./wandb/offline-run-20211222_192214-3go72k41/logs/debug.log\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 193, in _run_module_as_main\n",
            "    \"__main__\", mod_spec)\n",
            "  File \"/usr/lib/python3.7/runpy.py\", line 85, in _run_code\n",
            "    exec(code, run_globals)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 261, in <module>\n",
            "    main()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/distributed/launch.py\", line 257, in main\n",
            "    cmd=cmd)\n",
            "subprocess.CalledProcessError: Command '['/usr/bin/python3', '-u', 'src/caption.py', '--local_rank=0', '--distributed', '--multiGPU', '--train', 'karpathy_train', '--valid', 'karpathy_val', '--test', 'karpathy_test', '--optim', 'adamw', '--warmup_ratio', '0.1', '--clip_grad_norm', '5', '--lr', '5e-5', '--epochs', '20', '--num_workers', '4', '--backbone', 't5-base', '--output', 'snap/COCOCaption/VLT5', '--load', 'snap/pretrain/VLT5/Epoch30', '--num_beams', '5', '--batch_size', '80', '--valid_batch_size', '100']' returned non-zero exit status 1.\n"
          ]
        }
      ]
    }
  ]
}