{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "blg561e_final_project_coco.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFToNDeuqE9v"
      },
      "source": [
        "# COCO Experiment by using pre-trained VL-BART and VL-T5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgSUhoRppsQI"
      },
      "source": [
        "## Download code and install dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JMqvnesGnXG",
        "outputId": "95a6fa86-e52e-47f6-940b-7ee6aea718e8"
      },
      "source": [
        "!git clone https://github.com/j-min/VL-T5\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VL-T5'...\n",
            "remote: Enumerating objects: 229, done.\u001b[K\n",
            "remote: Counting objects: 100% (229/229), done.\u001b[K\n",
            "remote: Compressing objects: 100% (135/135), done.\u001b[K\n",
            "remote: Total 229 (delta 132), reused 177 (delta 89), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (229/229), 900.48 KiB | 8.42 MiB/s, done.\n",
            "Resolving deltas: 100% (132/132), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9n42_sfxXByh",
        "outputId": "6aa00a36-c3b9-4366-eb6a-960ee30a2f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_data  VL-T5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U25Mz51oRxJH",
        "outputId": "ce64e619-c807-4c99-bfdd-d8c6e78c9d78"
      },
      "source": [
        "!pip uninstall param -y # to resolve name conflict with src.param.py\n",
        "!pip install -r VL-T5/requirements.txt\n",
        "!python VL-T5/download_backbones.py"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: param 1.12.0\n",
            "Uninstalling param-1.12.0:\n",
            "  Successfully uninstalled param-1.12.0\n",
            "Collecting git+git://github.com/j-min/language-evaluation@master (from -r VL-T5/requirements.txt (line 12))\n",
            "  Cloning git://github.com/j-min/language-evaluation (to revision master) to /tmp/pip-req-build-spabjnhr\n",
            "  Running command git clone -q git://github.com/j-min/language-evaluation /tmp/pip-req-build-spabjnhr\n",
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 19 kB/s \n",
            "\u001b[?25hCollecting transformers==4.2.1\n",
            "  Downloading transformers-4.2.1-py3-none-any.whl (1.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.8 MB 42.2 MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 47.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 4)) (3.1.0)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.12.9-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 23.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 6)) (4.62.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 7)) (1.19.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 8)) (1.1.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 9)) (3.2.2)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from -r VL-T5/requirements.txt (line 10)) (3.13)\n",
            "Collecting sacrebleu\n",
            "  Downloading sacrebleu-2.0.0-py3-none-any.whl (90 kB)\n",
            "\u001b[K     |████████████████████████████████| 90 kB 9.6 MB/s \n",
            "\u001b[?25hCollecting torchvision==0.7.0\n",
            "  Downloading torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.9 MB 33.8 MB/s \n",
            "\u001b[?25hCollecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (0.18.3)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (0.12.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (1.15.0)\n",
            "Requirement already satisfied: more_itertools in /usr/local/lib/python3.7/dist-packages (from language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (8.12.0)\n",
            "Collecting colorlog\n",
            "  Downloading colorlog-6.6.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r VL-T5/requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (3.4.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.47-py2.py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 46.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (4.10.0)\n",
            "Collecting tokenizers==0.9.4\n",
            "  Downloading tokenizers-0.9.4-cp37-cp37m-manylinux2010_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 39.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0->-r VL-T5/requirements.txt (line 13)) (7.1.2)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->-r VL-T5/requirements.txt (line 4)) (1.5.2)\n",
            "Collecting yaspin>=1.0.0\n",
            "  Downloading yaspin-2.1.0-py3-none-any.whl (18 kB)\n",
            "Collecting shortuuid>=0.5.0\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from wandb->-r VL-T5/requirements.txt (line 5)) (2.8.2)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r VL-T5/requirements.txt (line 5)) (7.1.2)\n",
            "Collecting sentry-sdk>=1.0.0\n",
            "  Downloading sentry_sdk-1.5.3-py2.py3-none-any.whl (142 kB)\n",
            "\u001b[K     |████████████████████████████████| 142 kB 45.9 MB/s \n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting configparser>=3.8.1\n",
            "  Downloading configparser-5.2.0-py3-none-any.whl (19 kB)\n",
            "Collecting subprocess32>=3.5.3\n",
            "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
            "\u001b[K     |████████████████████████████████| 97 kB 5.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r VL-T5/requirements.txt (line 5)) (2.3)\n",
            "Collecting pathtools\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "Collecting GitPython>=1.0.0\n",
            "  Downloading GitPython-3.1.26-py3-none-any.whl (180 kB)\n",
            "\u001b[K     |████████████████████████████████| 180 kB 48.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r VL-T5/requirements.txt (line 5)) (3.17.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from wandb->-r VL-T5/requirements.txt (line 5)) (5.4.8)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.9-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from GitPython>=1.0.0->wandb->-r VL-T5/requirements.txt (line 5)) (3.10.0.2)\n",
            "Collecting smmap<6,>=3.0.1\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: termcolor<2.0.0,>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from yaspin>=1.0.0->wandb->-r VL-T5/requirements.txt (line 5)) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r VL-T5/requirements.txt (line 8)) (2018.9)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r VL-T5/requirements.txt (line 9)) (3.0.6)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r VL-T5/requirements.txt (line 9)) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r VL-T5/requirements.txt (line 9)) (0.11.0)\n",
            "Collecting portalocker\n",
            "  Downloading portalocker-2.3.2-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->-r VL-T5/requirements.txt (line 11)) (0.8.9)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (3.7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.2.1->-r VL-T5/requirements.txt (line 2)) (1.1.0)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (1.4.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (1.2.0)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (2.6.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->language-evaluation==0.1.0->-r VL-T5/requirements.txt (line 12)) (2021.11.2)\n",
            "Building wheels for collected packages: language-evaluation, subprocess32, wget, pathtools\n",
            "  Building wheel for language-evaluation (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for language-evaluation: filename=language_evaluation-0.1.0-py3-none-any.whl size=42700525 sha256=82f2f9cdc51f0b77293cd7a52c37ad380cfdde0b63c228d17af4a71acd98107b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ujpztx87/wheels/8d/fd/6b/f12f08f2fca4312f96a38e1df7c5f5fbebb59480def23f6cb7\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6502 sha256=9fa3cbcd360a3524227fdd9ded3c4be92802bfe1c259986aa2ccd2fc8214c703\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9675 sha256=3fe23ef3ada972eb1eac91a6ebdbba388d42f8bbab9e53e7b3fdde204f877a5c\n",
            "  Stored in directory: /root/.cache/pip/wheels/a1/b6/7c/0e63e34eb06634181c63adacca38b79ff8f35c37e3c13e3c02\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8806 sha256=a0c4aa1fa5cdf1ba625b76e6c30e6e93f0b50ff422b3027193ffb1d1ada06e12\n",
            "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
            "Successfully built language-evaluation subprocess32 wget pathtools\n",
            "Installing collected packages: smmap, gitdb, yaspin, torch, tokenizers, subprocess32, shortuuid, sentry-sdk, sacremoses, portalocker, pathtools, GitPython, docker-pycreds, configparser, colorlog, colorama, wget, wandb, transformers, torchvision, sentencepiece, sacrebleu, language-evaluation\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.11.1+cu111\n",
            "    Uninstalling torchvision-0.11.1+cu111:\n",
            "      Successfully uninstalled torchvision-0.11.1+cu111\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\u001b[0m\n",
            "Successfully installed GitPython-3.1.26 colorama-0.4.4 colorlog-6.6.0 configparser-5.2.0 docker-pycreds-0.4.0 gitdb-4.0.9 language-evaluation-0.1.0 pathtools-0.1.2 portalocker-2.3.2 sacrebleu-2.0.0 sacremoses-0.0.47 sentencepiece-0.1.96 sentry-sdk-1.5.3 shortuuid-1.0.8 smmap-5.0.0 subprocess32-3.5.4 tokenizers-0.9.4 torch-1.6.0 torchvision-0.7.0 transformers-4.2.1 wandb-0.12.9 wget-3.2 yaspin-2.1.0\n",
            "Downloading checkpoints if not cached\n",
            "T5-base\n",
            "Downloading: 100% 1.20k/1.20k [00:00<00:00, 1.19MB/s]\n",
            "Downloading: 100% 892M/892M [00:22<00:00, 39.0MB/s]\n",
            "Downloading: 100% 792k/792k [00:00<00:00, 4.43MB/s]\n",
            "BART-base\n",
            "Downloading: 100% 899k/899k [00:00<00:00, 5.13MB/s]\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.17MB/s]\n",
            "Downloading: 100% 1.69k/1.69k [00:00<00:00, 1.28MB/s]\n",
            "Downloading: 100% 558M/558M [00:14<00:00, 38.9MB/s]\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIcGYw4HqSGW"
      },
      "source": [
        "## Download the pretrained checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdBlncooUJY4"
      },
      "source": [
        "import gdown"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXR4YwyiUvp7"
      },
      "source": [
        "!mkdir -p  /content/VL-T5/VL-T5/snap/pretrain/VLT5\n",
        "!mkdir -p  /content/VL-T5/VL-T5/snap/pretrain/VLBart\n",
        "#!mkdir -p snap/vcr_pretrain/VLBart\n",
        "#!mkdir -p snap/vcr_pretrain/VLT5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "X1aNEiF3UkRE",
        "outputId": "733dcfd1-19b3-4c0f-a822-9e74abd52ce4"
      },
      "source": [
        "gdown.download('https://drive.google.com/uc?id=1HYdYaU1MRonlN0j4par6aOpgScTlKbGV', '/content/VL-T5/VL-T5/snap/pretrain/VLT5/Epoch30.pth', quiet=False)\n",
        "gdown.download('https://drive.google.com/uc?id=1F02ow1Ie3IkhumyoiFRVpMW-mXHPx-42', '/content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30.pth', quiet=False)\n",
        "# gdown.download('https://drive.google.com/uc?id=1jnYApPfQKtzg3vYBZ377-mkZi2_wvu_d', '/content/VL-T5/VL-T5/snap/vcr_pretrain/VLT5/Epoch20.pth', quiet=False)\n",
        "# gdown.download('https://drive.google.com/uc?id=1x41tvojah910rzH8wz9Be3-5mzWTD1-q', '/content/VL-T5/VL-T5/snap/vcr_pretrain/VLBart/Epoch20.pth', quiet=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1HYdYaU1MRonlN0j4par6aOpgScTlKbGV\n",
            "To: /content/VL-T5/VL-T5/snap/pretrain/VLT5/Epoch30.pth\n",
            "100%|██████████| 898M/898M [00:09<00:00, 94.8MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1F02ow1Ie3IkhumyoiFRVpMW-mXHPx-42\n",
            "To: /content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30.pth\n",
            "100%|██████████| 565M/565M [00:11<00:00, 48.3MB/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30.pth'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hcXsM8fzxozN"
      },
      "source": [
        "Download datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uSZQxFrEy4FV",
        "outputId": "0b71c6ad-6ba1-4b51-f549-97fcd82b6305"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls /content/gdrive/MyDrive/datasets"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "COCO  flickr30k  GQA  lxmert  nlvr  RefCOCO  VCR  VG  vqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r '/content/gdrive/MyDrive/datasets' '/content/VL-T5/'\n",
        "!ls '/content/VL-T5/datasets'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EOW8Zyb6Ypzm",
        "outputId": "e9e79d8a-d009-4910-a4b7-1fd4c2a84ffc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "COCO  flickr30k  GQA  lxmert  nlvr  RefCOCO  VCR  VG  vqa\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls '/content/VL-T5/datasets/VCR'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ej4ZsQjoEaaT",
        "outputId": "0ad69c6b-5498-4b0a-c1d3-40b9d7952a5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features  test.jsonl  train.jsonl  val.jsonl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/VL-T5/VL-T5/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Q7smxWbG4gU",
        "outputId": "1b37f074-2f3c-4c8c-d469-686b8ad046f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VL-T5/VL-T5/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fU8OOPPoHMR5",
        "outputId": "b598e347-779a-4bb1-cbe5-7580f4a97989"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "caption_data.py   modeling_bart.py    pretrain_data.py\t    tokenization.py\n",
            "caption_model.py  modeling_t5.py      pretrain_model.py     trainer_base.py\n",
            "caption.py\t  multitask_data.py   pretrain.py\t    utils.py\n",
            "dist_utils.py\t  multitask_model.py  pretrain_vcr_data.py  vcr_data.py\n",
            "gqa_data.py\t  multitask.py\t      pretrain_vcr.py\t    vcr_model.py\n",
            "gqa_model.py\t  nlvr_data.py\t      qa_answer_table.py    vcr.py\n",
            "gqa.py\t\t  nlvr_model.py       refcoco_data.py\t    vqa_data.py\n",
            "mmt_data.py\t  nlvr.py\t      refcoco_model.py\t    vqa_model.py\n",
            "mmt_model.py\t  param.py\t      refcoco.py\t    vqa.py\n",
            "mmt.py\t\t  preprocess.py       refcoco_utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  /content/VL-T5/VL-T5/snap/pretrain/VLT5"
      ],
      "metadata": {
        "id": "OPEWAJJ7HcfC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls  /content/VL-T5/VL-T5/snap/pretrain/VLBart"
      ],
      "metadata": {
        "id": "7DxN16QSZAxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VL-T5 on COCO"
      ],
      "metadata": {
        "id": "X1U7KOlYcI0C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/VL-T5/VL-T5/src"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXynZUqEmo3f",
        "outputId": "e156c400-b911-46b6-c2d5-fbda74328f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/VL-T5/VL-T5/src\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from caption import Trainer\n",
        "from caption_data import get_loader\n",
        "from param import parse_args\n",
        "import os\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
      ],
      "metadata": {
        "id": "QgYK15LNHQR-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vl_t5_args = parse_args(\n",
        "    parse=False,\n",
        "    backbone='t5-base',\n",
        "    load='/content/VL-T5/VL-T5/snap/pretrain/VLT5/Epoch30',\n",
        "    gpu = 0,\n",
        ")\n",
        "valid_batch_size = 10"
      ],
      "metadata": {
        "id": "G-VP4rscmbyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Building test submit loader at GPU {0}')\n",
        "vl_t5_test_loader = get_loader(\n",
        "  vl_t5_args,\n",
        "  split='test', mode='test', batch_size=valid_batch_size,\n",
        "  gpu=vl_t5_args.gpu,\n",
        "  workers=4,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pm3fU2qeIyAh",
        "outputId": "8e517e3f-a7f6-4c19-93ba-0a8d1e51c001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building test submit loader at GPU 0\n",
            "Data source:  test\n",
            "test has 5000 images\n",
            "Loaded 5000 data from test\n",
            "# all sentences: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl_t5_trainer = Trainer(\n",
        "    vl_t5_args,\n",
        "    train=False,\n",
        "    test_loader=vl_t5_test_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mipC-lghTUKV",
        "outputId": "dd1be80a-e773-4e2e-997a-49c0dc14ab19"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Model at GPU 0\n",
            "Model loaded from  /content/VL-T5/VL-T5/snap/pretrain/VLT5/Epoch30.pth\n",
            "_IncompatibleKeys(missing_keys=[], unexpected_keys=['encoder.visual_embedding.layer_norm.weight'])\n",
            "Model Launching at GPU 0\n",
            "It took 0.8s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl_t5_acc_dict = vl_t5_trainer.evaluate(vl_t5_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 623
        },
        "id": "lxbbCC0XT-VT",
        "outputId": "fb5918df-ac71-4633-b6c0-fce4437c8a6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Prediction:   0%|                                                                               | 0/500 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-1e7167af7499>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvl_t5_acc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvl_t5_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl_t5_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/content/VL-T5/VL-T5/src/caption.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, loader, dump_path)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdump_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/VL-T5/VL-T5/src/caption.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, loader, dump_path)\u001b[0m\n\u001b[1;32m    342\u001b[0m             \u001b[0mgen_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'max_length'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_max_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Prediction\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistributed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1180\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1181\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    987\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m                 \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_task_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 989\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1012\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_put_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1015\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_utils.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0;31m# (https://bugs.python.org/issue2651), so we work around it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKeyErrorMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: Caught KeyError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/worker.py\", line 185, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/content/VL-T5/VL-T5/src/caption_data.py\", line 176, in __getitem__\n    img_h = f[f'{img_id}/img_h'][()]\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"/usr/local/lib/python3.7/dist-packages/h5py/_hl/group.py\", line 288, in __getitem__\n    oid = h5o.open(self.id, self._e(name), lapl=self._lapl)\n  File \"h5py/_objects.pyx\", line 54, in h5py._objects.with_phil.wrapper\n  File \"h5py/_objects.pyx\", line 55, in h5py._objects.with_phil.wrapper\n  File \"h5py/h5o.pyx\", line 190, in h5py.h5o.open\nKeyError: \"Unable to open object (file read failed: time = Sun Jan 23 13:11:49 2022\\n, filename = '/content/gdrive/.shortcut-targets-by-id/1MBBhlkP83VMKS2Qe0SmFfzkHhMpIG5wf/datasets/COCO/features/val2014_obj36.h5', file descriptor = 101, errno = 5, error message = 'Input/output error', buf = 0x55e7c6e44f40, total read size = 544, bytes this sub-read = 544, bytes actually read = 18446744073709551615, offset = 0)\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"VL-T5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HOoWtCnOXlhg",
        "outputId": "357c7e4c-18d0-4b11-d77a-d827cc6795d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "VL-T5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# VL-BART on COCO"
      ],
      "metadata": {
        "id": "EuVVIU7IjfuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from caption import Trainer\n",
        "from caption_data import get_loader\n",
        "from param import parse_args\n",
        "import os\n",
        "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
      ],
      "metadata": {
        "id": "LUqXAcxZjKKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vl_bart_args = parse_args(\n",
        "    parse=False,\n",
        "    backbone='facebook/bart-base',\n",
        "    load='/content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30',\n",
        "    gpu = 0,\n",
        ")\n",
        "valid_batch_size = 10"
      ],
      "metadata": {
        "id": "iEYwUKvIjXUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Building test submit loader at GPU {0}')\n",
        "vl_bart_test_loader = get_loader(\n",
        "  vl_bart_args,\n",
        "  split='test', mode='test', batch_size=valid_batch_size,\n",
        "  gpu=vl_bart_args.gpu,\n",
        "  workers=4,\n",
        "  \n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTV3na3zh6Vn",
        "outputId": "1775aa06-be64-40a8-f522-b439522f2f62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building test submit loader at GPU 0\n",
            "Data source:  test\n",
            "test has 5000 images\n",
            "Loaded 5000 data from test\n",
            "# all sentences: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl_bart_trainer = Trainer(\n",
        "    vl_bart_args,\n",
        "    train=False,\n",
        "    test_loader=vl_bart_test_loader\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKHcFUFdaf4F",
        "outputId": "fa549533-3301-426b-8cae-5597f77501fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Building Model at GPU 0\n",
            "Model loaded from  /content/VL-T5/VL-T5/snap/pretrain/VLBart/Epoch30.pth\n",
            "_IncompatibleKeys(missing_keys=['model.encoder.visual_embedding.feat_embedding.1.weight', 'model.encoder.visual_embedding.feat_embedding.1.bias', 'model.encoder.visual_embedding.absolute_vis_pos_embedding.1.weight', 'model.encoder.visual_embedding.absolute_vis_pos_embedding.1.bias'], unexpected_keys=['model.encoder.visual_embedding.layer_norm.weight', 'model.encoder.visual_embedding.layer_norm.bias'])\n",
            "Model Launching at GPU 0\n",
            "It took 0.3s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vl_bart_acc_dict = vl_bart_trainer.evaluate_test(vl_bart_test_loader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "p3dUkQrzaf_4",
        "outputId": "15d7b135-bb33-4296-839f-dfecd8077fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-84c91ecf2e7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvl_bart_acc_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvl_bart_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvl_bart_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'evaluate_test'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"VL-Bart\")\n"
      ],
      "metadata": {
        "id": "b3dChKORagGo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "LW18QwM7agOF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}